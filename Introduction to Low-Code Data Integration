# Introduction to Data Modelling
Data modeling is a critical process in software development, especially within low-code platforms like Microsoft Power Platform. It involves defining how data is structured, stored, and related to ensure efficient storage, retrieval, and processing for various applications. This foundational step helps developers and organizations create robust, scalable, and efficient systems that meet specific business needs.
Low-code platforms prioritize ease of use and rapid development, and effective data modeling plays a vital role in enabling these platforms to deliver seamless and data-driven solutions.
The process of defining how data is structured, stored, and related to enable efficient storage and retrieval for various applications.

## Importance in Low-Code Platforms:
- Facilitates app development by providing a structured foundation for data-driven solutions.
- Enhances data consistency and integrity through clearly defined relationships and constraints.
- Enables seamless data integration with multiple sources, ensuring that applications can access and utilize the required information effectively.
- Supports scalability and performance optimization by designing data models that align with app requirements.

---

# Components of Data Modelling and the ETL/ELT Process
The ETL (Extract, Transform, Load) or ELT (Extract, Load, Transform) process is a cornerstone of data management and integration. It is used to optimize workflows and maintain data integrity by moving data from source systems to a centralized repository or target system for analysis, reporting, or other business needs. This process ensures data is accessible, consistent, and prepared for use in decision-making and application development.
Integrating these ETL/ELT components ensures data workflows are efficient, secure, and ready to support scalable, data-driven applications.

To optimize workflows and maintain data integrity, it is crucial to integrate best practices from the ETL (Extract, Transform, Load) or the ELT (Extract, Load, Transform) process.

## Key Steps:
1. **Extract:**
   - Gather raw data from diverse sources (e.g., SharePoint, SQL Server, Excel).
   - Ensure proper security protocols during extraction, such as OAuth authentication.

2. **Transform:**
   - Clean, enrich, and structure data using tools like Power Query.
   - Apply common transformations: removing duplicates, modifying data types, and merging columns.

3. **Load:**
   - Push prepared data into Dataverse or other storage solutions.
   - Schedule automatic refreshes to maintain updated datasets.

## Best Practices for ETL in Power Platform:
- Leverage Power Query for consistent and reusable transformations.
- Utilize Dataflows for automated and scalable ETL processes.
- Monitor performance and optimize queries for increasing data volumes.
- Ensure data governance through DLP policies and secure connectors.

---

# Data Modelling Principles in Power Platform
Data modeling principles in the Power Platform are essential for creating applications that are reliable, efficient, and secure. These principles ensure that the underlying data is accurate, scalable, and protected, allowing organizations to build solutions that meet performance and compliance requirements. Effective implementation of these principles promotes the seamless integration and management of data across various systems.
## Key Principles:
- **Normalization:** Organize data to reduce redundancy and improve integrity.
- **Relationships:** Clearly define one-to-one, one-to-many, or many-to-many relationships using appropriate keys.
- **Consistency:** Maintain consistent naming conventions and align data types with intended use.
- **Data Integrity:** Enforce validation rules and use business logic to ensure data accuracy.
- **Scalability:** Design models to handle increasing data volumes efficiently.
- **Security:** Implement role-based access controls and DLP policies to secure sensitive data.

---

# Connecting to Data Sources

## Power Platform Architecture:


This diagram illustrates the architecture and security framework supporting Microsoft Power Platform, emphasizing infrastructure, tenant-level security, connector-level security, and cloud expansion.

The architecture highlights:
- **Power Platform:** Low-code suite for app development, automation, and analytics.
- **API Management:** Streamlines API use and ensures secure interactions.
- **Connectors:** Bridge Power Platform apps and data sources using Azure Functions.
- **Data Sources:** Azure-hosted or external sources providing underlying data.

## Security Layers:
1. **Tenant-Level Security:**
   - Azure Active Directory (Azure AD) access control.
   - Multi-Factor Authentication (MFA).
   - Data Loss Prevention (DLP) policies.

2. **Connector-Level Security:**
   - Basic Authentication, JWT Token, OAuth, and API Keys.

3. **Cloud Expansion:**
   - Supports Azure, Google Cloud, AWS, and IBM Cloud for hybrid and multi-cloud strategies.

---

# Power Platform Connectors

As of October 2024, Microsoft Power Platform offers over 1,300 connectors enabling seamless integration with services and data sources.

## Types of Connectors:
- **Standard Connectors:** Included in base licenses, supporting widely used Microsoft services.
- **Premium Connectors:** Require additional licensing and support advanced integrations like Salesforce and SAP.

---

# Internal & External Data Sources

## Types:
- **Internal Sources:** Microsoft ecosystem (e.g., Dataverse, SharePoint).
- **External Sources:** Third-party systems (e.g., SQL Server, REST APIs).

## Data Connection Methods:
1. **Direct Connections:** Real-time access to live data.
2. **Import Connections:** Static snapshots of data for batch processing.

---

# Introduction to Power Query

Power Query is a tool for transforming and preparing data for analysis.

## Key Features:
- Clean and filter data.
- Combine multiple data sources.
- Perform transformations like grouping and merging.

---

# Introduction to DAX (Data Analysis Expressions)

DAX is a formula language for creating custom calculations and analytical expressions.

## Key Features:
- Create measures and calculated columns.
- Enable time intelligence for analyzing trends.
- Support advanced logic and expressions.

## Common Functions:
- **Aggregation:** `SUM`, `AVERAGE`, `MIN`, `MAX`.
- **Logical:** `IF`, `AND`, `OR`.
- **Time Intelligence:** `YEAR`, `MONTH`, `TODAY`.

---

# Introduction to Dataflows

Dataflows extract, transform, and load (ETL) data into Dataverse or Power BI.

### Components:
1. **Data Sources:** SQL Server, Excel, SharePoint, REST APIs.
2. **Transformations:** Performed with Power Query.
3. **Destinations:** Dataverse, Power BI, or external databases.

---
